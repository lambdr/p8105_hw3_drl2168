---
title: 'P8105: Homework 3'
author: "Derek Lamb"
date: "`r Sys.Date()`"
output: github_document
---

I will load all necessary packages here. I also am including the code that Dr. Goldsmith showed in class, to set figure color and size preferences. I have modified it slightly: I prefer `theme_bw()` over `theme_minimal()` and I may change the color scheme from the default `viridis`.
```{r load packages, message = FALSE}
library(tidyverse)
library(knitr)
library(p8105.datasets)

opts_chunk$set(
  fig.width = 6,
  out.width = "90%"
)

## These are options that i'm going to treat as default for now
## I don't love viridis, but don't have a better option yet
theme_set(theme_bw() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
```{r instacart data import}
# Load data from the provided package
data("instacart")
```

### Data set size, user behavior
This data set is massive, containing `r nrow(instacart)` observations of `r ncol(instacart)` variables. Each row is a specific item from an order, in total `r instacart |> pull(order_id) |> unique() |> length()` orders are included from `r instacart |> pull(user_id) |> unique() |> length()` unique users. There appear to be no repeat orders from users in this data set, although `r instacart |> pull(reordered) |> sum()` items are items that were previously ordered by that user. This accounts for `r (instacart |> pull(reordered) |> sum()/nrow(instacart)) |> scales::percent()` of the orders, showing that only a small portion of instacart activity is captured by this data set. There are no first-time orders in this data set; this is on average order number `r instacart |> pull(order_number) |> mean() |> round(digits = 0)` for users (median order number `r instacart |> pull(order_number) |> median()` ). On average, users placed their orders `r instacart |> pull(days_since_prior_order) |> mean() |> round(digits = 1)` days after their previous one.

### Aisles & products
There are `r instacart |> pull(aisle_id) |> unique() |> length()` unique aisles included in the data set. In the following code chunk, I'll find the most ordered from aisles.
```{r aisle orders}
instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n()) |> 
  arrange(desc(n_obs)) |> 
  head() |> 
  kable(col.names = c("Aisle", "Number of Orders"))
```
The two most ordered from aisles are fresh vegetables and fresh fruits, with about 150,000 orders each. Below, you can see a plot of all aisles with more than 10,000 orders.

```{r aisle plot}
instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n()) |> 
  filter(n_obs >=10000) |> 
  ggplot(aes(y = reorder(aisle, n_obs), x = n_obs)) +
  geom_bar(alpha = .9, stat = "identity") + 
  labs(
    title = "Instacart aisles with more than 10,000 orders",
    x = "Number of orders",
    y = "Aisle"
  )
```

To look more closely at the data set, I created a table examining the three most popular items from a set of aisles.
```{r most pop items in 3 rows, message = FALSE}
instacart |> 
  group_by(aisle, product_name) |> 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") |> 
  summarize(n_obs = n()) |> 
  filter(min_rank(desc(n_obs)) <= 3) |> 
  mutate(
    rank = min_rank(desc(n_obs)),
    item = paste(product_name, " (", as.character(n_obs),")", sep = "")
         ) |> 
  select(-product_name, -n_obs) |> 
  pivot_wider(
    names_from = aisle,
    values_from = item
  ) |> 
  arrange(rank) |> 
  kable(col.names = c("Rank in Aisle", "Baking Ingredients", "Dog Food & Care", "Packaged Vegatables & Fruits"), caption = "Item (# of orders)")
```

### Apples & Ice Cream
```{r pink lady}
instacart |> 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") |> 
  group_by(product_name, order_dow) |> 
  summarize(avg_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = avg_hour
  ) |> 
  kable(digits = 1, col.names = c("Product", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

While the majority of ordering appears concentrated in the midle of the day, coffee ice cream is bought a bit later in the afternoon, particularly during Weekdays.


# Problem 2
In the code chunk below, I will load the data for this problem, filter `topic` to just Overall Health, and recode `response` as a factor variable. 
```{r brfss data import}
data("brfss_smart2010") 
df_brfss = brfss_smart2010|> 
  janitor::clean_names() |>
  filter(topic == "Overall Health")|> 
  mutate(response = factor(response, levels=c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

### Number of sites
I will look at the number of sites per state.
```{r number of states 2002}
df_brfss |> 
  filter(year == 2002) |> 
  group_by(locationabbr) |> 
  summarize(n_site = n_distinct(locationdesc)) |> 
  filter(n_site >= 7) |> 
  pull(locationabbr)

```

These 6 states have 7 or more locations sampled within them in 2002, whereas there were 14 states that had 7 or more locations in 2010:

```{r number of states 2010}
df_brfss |> 
  filter(year == 2010) |> 
  group_by(locationabbr) |> 
  summarize(n_site = n_distinct(locationdesc)) |> 
  filter(n_site >= 7) |> 
  pull(locationabbr)
```

There are now 14 states with 7 or more sites, 8 more than in 2002. Of note, 9 states have entered this group, and Connecticut has actually decreased down to 5 sites.

### Excellence over Time
In the plot below, I have graphed the percentage of excellent answers to questions about Overall Health over time, from 2002 to 2010. The response are separated by state, and represent an average across the locations within the state. There appears to be a slight downward trend, but it is not immediately apparent within the noise of the data.

```{r brfss spaghetti plot, message = FALSE, warning = FALSE}
df_brfss |> 
  filter(response == "Excellent") |> 
  group_by(year, locationabbr) |> 
  summarize(avg_excellent = mean(data_value)) |> 
  ggplot(aes(x = year, y = avg_excellent, group = locationabbr, color = locationabbr)) +
  geom_line() +
  labs(
    title = "Spaghetti Plot of BFRSS Excellent Scores over Time",
    x = "Year",
    y = "Excellent Health (%)"
  ) + 
  theme(legend.position = "none")

```

### NY State
For the following I filtered the data to only New York responses in 2006 and 2010. I then plotted the distribution of scores over the years, coloring by County.
```{r distribution}
df_brfss |> 
  filter(locationabbr == "NY" & (year == 2006 | year == 2010)) |> 
  separate(locationdesc, into = c("state", "county"), "-") |> 
  select(year, county, response, data_value) |> 
  ggplot(aes(x = response,  y = data_value)) + 
  geom_boxplot() +
  geom_point(aes(color = county))+
  facet_grid(. ~ year)

```

# Problem 3
I will import `nhanes_covar.csv`, then `nhanes_accel.csv`, and then combine the two after some preliminary tidying. In `nhanes_covar.csv`, I changed variable names to snake case and recoded `sex` and `education` to character variables. The `bmi` and `education` variables are missing data for some subjects, but the missing data were appropriately labelled as `NA` so I didn't need to make any changes there.

The only modification I needed to make to `nhanes_accel.csv` was changing the `seqn` indicator variable name to be lower case. I think that R is handling the scientific notation of some columns correctly. If this proves to be a problem, I will address it later.
```{r import nhanes data, message = FALSE}
# Import and tidy covariate info
df_subjects <- read_csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(sex,
                     1 ~ "Male",
                     2 ~ "Female"
                     ),
    education = case_match(education,
                           1 ~ "Incomplete High School",
                           2 ~ "Complete High School",
                           3 ~ "Post High School"
                           )) 

# Import and tidy accelerometer info
df_accel <- read_csv("data/nhanes_accel.csv") |> 
  janitor::clean_names()
```

I have verified that the same 250 subjects are present in both data sets. It therefore doesn't matter which of the `._join()` functions I use. I will now combine these two dataframes and then convert the accelerometer data from a wide to a long format. The assignment also specifies to exclude individuals younger than 21, or those with missing demographic data, so I will do that now as well.

```{r combine nhanes dataframes}
df_nhanes <- left_join(df_subjects, df_accel, by = join_by(seqn)) |> 
  pivot_longer(min1:min1440,
    names_to = "min",
    values_to = "acceleration",
    names_prefix = "min"
  ) |> 
  mutate(min = as.numeric(min),
        education = fct_relevel(education, c("Incomplete High School", "Complete High School", "Post High School"))
  ) |> 
  filter(age >= 21) |> 
  drop_na(education)
```

This final dataframe contains `r nrow(df_nhanes)` observations of `r ncol(df_nhanes)` variables. It records basic demographic information, such as `age`, `sex`, and `education` along with `bmi` for `r df_nhanes |> pull(seqn) |> unique() |> length()` subjects of the NHANES study. It then tracks a person's movement using an accelerometer every minute over the course of one day.

### Demographics
In order to better understand the participants in this study, I created a basic table of participants by `sex` and `education` variables.

```{r create demographic table}
df_nhanes |> 
  group_by(sex, education) |> 
  summarize(n_subj = n_distinct(seqn)) |> 
  pivot_wider(
    names_from = sex,
    values_from = n_subj
  ) |> 
  mutate(Total = Female + Male)|> 
  arrange(education) |> 
  kable()
  
```

About half of the participants have post-secondary education, and about a quarter each have only high school or incomplete high school education. The amount of males and females are approximately balanced, although there are about 50% more males than females with only high school diplomas. To further examine these demographic groups, and take into account age, I will create a figure below.

```{r age histogram by demographics}
df_nhanes |> 
  filter(min == 1) |> 
  ggplot(aes(x = age)) +
  geom_histogram(binwidth = 5) + 
  facet_grid(sex ~ education) + 
  labs(
    title = "NHANES Participant Ages",
    x = "Age (years)",
    y = "Number of Participants"
  )
```

I used `filter` to reduce the dataframe to the first observation of each subject. Since the accelerometer values aren't needed for this graph, it prevents overcounting each participant.

Participants without post-secondary education tend to be spread out more in age, while participants with post-secondary education tend to be younger, although those distriubtions are positively skewed.

### Movement
In order to examine total movement vs age, I grouped the dataframe by `seqn`, the subject ID, then used `mutate` to get the total movement for each individual, and then again used `filter` to reduce the dataframe to one row per participant. I did this instead of `summarize` because of the need to keep `sex` as a variable in the dataframe.
```{r movement vs age}
df_nhanes |> 
  group_by(seqn) |> 
  mutate(total_move = sum(acceleration)) |> 
  filter(min == 1) |> 
  ggplot(aes(x = age, y = total_move)) + 
  geom_point() +
  geom_smooth(
    method = "lm", 
    se = TRUE
    ) +
  facet_grid(. ~ sex) + 
    labs(
    title = "NHANES Participant Movement",
    x = "Age (years)",
    y = "Total Movement (MIMS Units)"
  )
```

This figure shows that there is a negative correlation between age and total movement, although there is substantial spread in the data. The slope looks smaller in magnitude for males than females, but I did not look at the model and model diagnostics outside of the plot.

```{r plot over day}
df_nhanes |> 
  mutate(time = min/60) |> 
  group_by(education, sex, time) |> 
  summarize(avg_move = mean(acceleration)) |> 
  ggplot(aes(x = time, y = avg_move, color = sex)) +
  geom_line(alpha = 0.4) +
  geom_smooth(alpha = 0.7, se = FALSE) + 
  facet_grid(education ~ .) +
    labs(
    title = "NHANES Daily Movement",
    x = "Time (hours)",
    y = "Total Movement (MIMS Units)",
    color = "Sex"
  )
```

